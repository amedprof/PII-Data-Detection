{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5a5fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Script/NLP/PII/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84bf958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import joblib\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff6482fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.cuda import amp\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    " \n",
    "from data.data_utils import to_gpu,to_np\n",
    "from data.dataset import FeedbackDataset,CustomCollator\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model_zoo.models import FeedbackModel,span_nms,aggregate_tokens_to_words\n",
    "from metrics_loss.metrics import score_feedback,score\n",
    "from transformers import get_linear_schedule_with_warmup,get_cosine_schedule_with_warmup,get_polynomial_decay_schedule_with_warmup,get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "\n",
    "from sklearn.metrics import log_loss \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils.utils import count_parameters\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7704609",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8895aef6",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d0104cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.json', 'test.json', 'sample_submission.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(r\"/database/kaggle/PII/data\")\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b34e2843",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = Path(r\"/database/kaggle/PII/checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c19b120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6807, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(data_path/'train.json')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4bfe6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                          full_text                                             tokens                                trailing_whitespace                                             labels\n",
       "0         7  Design Thinking for innovation reflexion-Avril...  [Design, Thinking, for, innovation, reflexion,...  [True, True, True, True, False, False, True, F...  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...\n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...  [True, False, False, True, True, False, False,...  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "922e6e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold,StratifiedGroupKFold,KFold,StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3eef037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_label'] = (df['labels'].transform(lambda x:len([i for i in x if i!=\"O\" ]))>0)*1\n",
    "seeds = [42]\n",
    "folds_names = []\n",
    "for K in [5]:  \n",
    "    for seed in seeds:\n",
    "        mskf = StratifiedKFold(n_splits=K,shuffle=True,random_state=seed)\n",
    "        name = f\"fold_sk_{K}_seed_{seed}\"\n",
    "        df[name] = -1\n",
    "        for fold, (trn_, val_) in enumerate(mskf.split(df,df['has_label'])):\n",
    "            df.loc[val_, name] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd28ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fff09a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL2TYPE = ('NAME_STUDENT','EMAIL','USERNAME','ID_NUM', 'PHONE_NUM','URL_PERSONAL','STREET_ADDRESS','O')\n",
    "for name in LABEL2TYPE[:-1]:\n",
    "    df[name] = ((df['labels'].transform(lambda x:len([i for i in x if i.split('-')[-1]==name ])))>0)*1\n",
    "\n",
    "seeds = [42]\n",
    "folds_names = []\n",
    "for K in [5]:  \n",
    "    for seed in seeds:\n",
    "        mskf = MultilabelStratifiedKFold(n_splits=K,shuffle=True,random_state=seed)\n",
    "        name = f\"fold_msk_{K}_seed_{seed}\"\n",
    "        df[name] = -1\n",
    "        for fold, (trn_, val_) in enumerate(mskf.split(df,df[list(LABEL2TYPE)[:-1]])):\n",
    "            df.loc[val_, name] = fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0ec52",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b98f9574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils import inference_step\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6308abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_TYPE = {\"0-0\":0,\"0-1\":1,\n",
    "           \"1-0\":2,\"1-1\":3,\n",
    "           \"2-0\":4,\"2-1\":5,\n",
    "           \"3-0\":6,\"3-1\":7,\n",
    "           \"4-0\":8,\"4-1\":9,\n",
    "           \"5-0\":10,\"5-1\":11,\n",
    "           \"6-0\":12,\"6-1\":12\n",
    "          }\n",
    "ID_NAME = {\"0-0\":\"B-NAME_STUDENT\",\"0-1\":\"I-NAME_STUDENT\",\n",
    "           \"1-0\":\"B-EMAIL\",\"1-1\":\"I-EMAIL\",\n",
    "           \"2-0\":\"B-USERNAME\",\"2-1\":\"I-USERNAME\",\n",
    "           \"3-0\":\"B-ID_NUM\",\"3-1\":\"I-ID_NUM\",\n",
    "           \"4-0\":\"B-PHONE_NUM\",\"4-1\":\"I-PHONE_NUM\",\n",
    "           \"5-0\":\"B-URL_PERSONAL\",\"5-1\":\"I-URL_PERSONAL\",\n",
    "           \"6-0\":\"B-STREET_ADDRESS\",\"6-1\":\"I-STREET_ADDRESS\"\n",
    "          }\n",
    "\n",
    "def inference_steps(df,folder,bs=1,fold=0):\n",
    "    \n",
    "    # ==== Loading Args =========== #\n",
    "    f = open(f'{folder}/params.json')\n",
    "    args = json.load(f)\n",
    "    args = SimpleNamespace(**args)\n",
    "    args.val_loader['batch_size'] = bs\n",
    "    args.model['pretrained_tokenizer'] = f\"{folder}/tokenizer\"\n",
    "    args.model['model_params']['config_path'] = f\"{folder}/config.pth\"\n",
    "    args.model['pretrained_weights'] = None\n",
    "    args.model[\"model_params\"]['pretrained_path'] = None\n",
    "#     args.model[\"model_params\"]['max_len'] = 3048\n",
    "    \n",
    "    args.device = 1\n",
    "    f.close()\n",
    "    device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # ==== Loading dataset =========== #\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.model[\"model_params\"]['model_name'])\n",
    "    valid_dataset = eval(args.dataset)(df,tokenizer,**args.data[\"params_valid\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ==== Loading checkpoints =========== #\n",
    "    checkpoints = [x.as_posix() for x in (Path(folder)).glob(\"*.pth\") if f\"fold_{fold}\" in x.as_posix()]\n",
    "    print(checkpoints)\n",
    "    weights = [1/len(checkpoints)]*len(checkpoints)\n",
    "    \n",
    "    \n",
    "    # ==== Loop Inference =========== #\n",
    "    doc_ids = []\n",
    "    tokens = []\n",
    "    predictions = None\n",
    "    gt_df = []\n",
    "    for j,(checkpoint,weight) in enumerate(zip(checkpoints,weights)):\n",
    "        net = FeedbackModel(**args.model[\"model_params\"])\n",
    "        net.load_state_dict(torch.load(checkpoint, map_location=lambda storage, loc: storage))\n",
    "        net = net.to(device)\n",
    "        net.eval()\n",
    "        \n",
    "        collator = CustomCollator(tokenizer,net)\n",
    "        val_loader = DataLoader(valid_dataset,**args.val_loader,collate_fn=collator)\n",
    "    \n",
    "\n",
    "        \n",
    "        preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(val_loader):\n",
    "                data = to_gpu(data, device)\n",
    "                \n",
    "                pred = net(data)\n",
    "                preds.append(pred.detach().cpu())\n",
    "#                 pred  = pred.softmax(-1)\n",
    "                \n",
    "                \n",
    "                if j==0:\n",
    "                \n",
    "                    doc_ids+=[data['text_id']]*pred.shape[0]\n",
    "                    tokens+=np.arange(pred.shape[0]).tolist()\n",
    "                    \n",
    "                    data = to_np(data)\n",
    "                    gt = pd.DataFrame({\n",
    "                                      \"document\":data['text_id'],\n",
    "                                      \"token\":np.arange(pred.shape[0]),\n",
    "                                      \"label\":data[\"gt_spans\"][:,1],\n",
    "                                      \"I\":data[\"gt_spans\"][:,2],\n",
    "                                     })\n",
    "                    gt_df.append(gt)\n",
    "\n",
    "        \n",
    "        if predictions is not None:\n",
    "#             predictions = torch.max(predictions,torch.cat(preds,dim=0))\n",
    "            predictions+= torch.cat(preds,dim=0)*weight\n",
    "        else:\n",
    "            predictions = torch.cat(preds,dim=0)*weight\n",
    "#             predictions+= torch.cat(preds,dim=0)*weight\n",
    "        print(predictions.shape)\n",
    "    \n",
    "    predictions = predictions.softmax(-1)\n",
    "    s,i = predictions.max(-1)\n",
    "    pred_df = pd.DataFrame({\"document\":doc_ids,\n",
    "                                 \"token\" : tokens,\n",
    "                                 \"label\" : i.numpy() ,\n",
    "                                 \"score\" : s.numpy() \n",
    "                                 })\n",
    "    \n",
    "    # ==== Loop Inference =========== #\n",
    "    del valid_dataset\n",
    "    del val_loader\n",
    "    del net\n",
    "    del s,i\n",
    "    del predictions\n",
    "\n",
    "    gc.collect()\n",
    "#     torch.cuda.empty_cache()\n",
    "    \n",
    "    # ==== Loop Inference =========== #\n",
    "#     pred_df = pred_df[(pred_df.label!=7) & (pred_df.score>0.5)].reset_index(drop=True)\n",
    "#     pred_df[\"I\"] = ((pred_df.groupby('document')['label'].transform(lambda x:x.diff())==0) & (pred_df.groupby('document')['token'].transform(lambda x:x.diff())==1))*1\n",
    "#     pred_df['labels'] = pred_df['label'].astype(str)+'-'+pred_df['I'].astype(str)\n",
    "#     pred_df[\"label_pred\"] = pred_df[\"labels\"].map(ID_TYPE).fillna(0).astype(int)\n",
    "#     pred_df['row_id'] = np.arange(len(pred_df))\n",
    "    \n",
    "\n",
    "    gt_df = pd.concat(gt_df,axis=0).reset_index(drop=True)\n",
    "    gt_df = gt_df[gt_df.label!=7].reset_index(drop=True)\n",
    "    gt_df['labels'] = gt_df['label'].astype(str)+'-'+gt_df['I'].astype(str)\n",
    "    gt_df[\"label_gt\"] = gt_df[\"labels\"].map(ID_TYPE).fillna(0).astype(int)\n",
    "    gt_df['row_id'] = np.arange(len(gt_df))\n",
    "\n",
    "    \n",
    "    \n",
    "    return pred_df , gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e28aa78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_2 _epoch_3 _step_5441 _valid_loss_0.0056 _score_0.9430 _train_loss_0.0037.pth',\n",
       " 'fold_4 _epoch_6 _step_4353 _valid_loss_0.0089 _score_0.9590 _train_loss_0.0010.pth',\n",
       " 'fold_0 _epoch_6 _step_5442 _valid_loss_0.0045 _score_0.9769 _train_loss_0.0011.pth',\n",
       " 'tokenizer',\n",
       " 'params.json',\n",
       " 'config.pth',\n",
       " 'fold_1 _epoch_5 _step_5442 _valid_loss_0.0118 _score_0.9443 _train_loss_0.0012.pth',\n",
       " 'fold_3 _epoch_6 _step_3810 _valid_loss_0.0129 _score_0.9345 _train_loss_0.0018.pth',\n",
       " 'tokenizer.zip']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLD_NAME = \"fold_msk_5_seed_42\"\n",
    "model_name = \"deberta-v3-large\"\n",
    "exp_name = \"2024-01-27--test\"\n",
    "folder = str(CHECKPOINT_PATH/Path(fr'{FOLD_NAME}/{model_name}/{exp_name}')) \n",
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34195a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    1362\n",
       "2    1362\n",
       "3    1361\n",
       "0    1361\n",
       "1    1361\n",
       "Name: fold_msk_5_seed_42, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[FOLD_NAME].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18e60b27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning : n SEP will be replace by | \n",
      "Loaded 1361 samples.\n",
      "['/database/kaggle/PII/checkpoint/fold_msk_5_seed_42/deberta-v3-large/2024-01-27--test/fold_0 _epoch_6 _step_5442 _valid_loss_0.0045 _score_0.9769 _train_loss_0.0011.pth']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7054b3b9bc044226ae07e39d270bee6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1361 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([997332, 8])\n"
     ]
    }
   ],
   "source": [
    "pred_df,gt_df = inference_steps(df[df[FOLD_NAME]==0],folder,bs=1,fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb6fc291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997332, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72d52a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540, 7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cccfb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['document', 'token', 'label', 'I', 'labels', 'label_gt', 'row_id'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b13acea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>I</th>\n",
       "      <th>labels</th>\n",
       "      <th>label_gt</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>204</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>324</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document  token  label  I labels  label_gt  row_id\n",
       "0        16      4      0  0    0-0         0       0\n",
       "1        16      5      0  1    0-1         1       1\n",
       "2        56     12      0  0    0-0         0       2\n",
       "3        56     13      0  1    0-1         1       3\n",
       "4       112      5      0  0    0-0         0       4\n",
       "5       112      6      0  1    0-1         1       5\n",
       "6       166      0      0  0    0-0         0       6\n",
       "7       166      1      0  1    0-1         1       7\n",
       "8       204      4      0  0    0-0         0       8\n",
       "9       324     13      0  0    0-0         0       9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2400f10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>I</th>\n",
       "      <th>labels</th>\n",
       "      <th>label_pred</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>8435</td>\n",
       "      <td>626</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>10422</td>\n",
       "      <td>371</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>1</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>9856</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1477</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>13103</td>\n",
       "      <td>147</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>0</td>\n",
       "      <td>5-0</td>\n",
       "      <td>10</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>5606</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>5433</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>6591</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1105</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>5452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     document  token  label  score  I labels  label_pred  row_id\n",
       "349      8435    626      0 0.9992  0    0-0           0     349\n",
       "479     10422    371      0 0.9996  1    0-1           1     479\n",
       "446      9856      8      0 0.9998  0    0-0           0     446\n",
       "30       1477      0      0 0.9998  0    0-0           0      30\n",
       "611     13103    147      5 0.9935  0    5-0          10     611\n",
       "184      5606     14      0 0.9996  1    0-1           1     184\n",
       "173      5433      7      0 0.9997  0    0-0           0     173\n",
       "249      6591    298      0 0.9993  0    0-0           0     249\n",
       "14       1105      6      0 0.9938  1    0-1           1      14\n",
       "175      5452      0      0 0.9997  0    0-0           0     175"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b57d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pred_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adf09ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = p.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4ac0c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(662, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pred_df[(pred_df.label!=7) & (pred_df.score>0.15)].reset_index(drop=True)\n",
    "pred_df[\"I\"] = ((pred_df.groupby('document')['label'].transform(lambda x:x.diff())==0) & (pred_df.groupby('document')['token'].transform(lambda x:x.diff())==1))*1\n",
    "pred_df['labels'] = pred_df['label'].astype(str)+'-'+pred_df['I'].astype(str)\n",
    "pred_df[\"label_pred\"] = pred_df[\"labels\"].map(ID_TYPE).fillna(0).astype(int)\n",
    "pred_df['row_id'] = np.arange(len(pred_df))\n",
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b84ad767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>I</th>\n",
       "      <th>labels</th>\n",
       "      <th>label_pred</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document  token           label  score  I labels  label_pred  row_id\n",
       "0        16      4  B-NAME_STUDENT 0.9999  0    0-0           0       0\n",
       "1        16      5  I-NAME_STUDENT 0.9998  1    0-1           1       1\n",
       "2        56     12  B-NAME_STUDENT 0.9998  0    0-0           0       2\n",
       "3        56     13  I-NAME_STUDENT 0.9996  1    0-1           1       3\n",
       "4       112      5  B-NAME_STUDENT 0.9998  0    0-0           0       4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60641702",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['label'] = pred_df['labels'].map(ID_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39b31225",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df['label'] = gt_df['labels'].map(ID_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "312c91b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_SUBS = [\"row_id\",'document', 'token', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa40abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL2TYPE = ('NAME_STUDENT','EMAIL','USERNAME','ID_NUM', 'PHONE_NUM','URL_PERSONAL','STREET_ADDRESS','O')\n",
    "LABEL = {l: t for l, t in enumerate(LABEL2TYPE)}\n",
    "\n",
    "def pii_fbeta_score_v2(pred_df, gt_df, beta=5):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - pred_df (DataFrame): DataFrame containing predicted PII labels.\n",
    "    - gt_df (DataFrame): DataFrame containing ground truth PII labels.\n",
    "    - beta (float): The beta parameter for the F-beta score, controlling the trade-off between precision and recall.\n",
    "\n",
    "    Returns:\n",
    "    - float: Micro F-beta score.\n",
    "    \"\"\"   \n",
    "\n",
    "    df = pred_df.merge(gt_df, how=\"outer\", on=[\"document\", \"token\"], suffixes=(\"_p\", \"_g\"))\n",
    "    df[\"cm\"] = \"\"\n",
    "    \n",
    "    df.loc[df.label_gt.isna(), \"cm\"] = \"FP\"\n",
    "    df.loc[df.label_pred.isna(), \"cm\"] = \"FN\"\n",
    "\n",
    "    # df.loc[(df.label_gt.notna()) & (df.label_gt != df.label_pred), \"cm\"] = \"FNFP\"\n",
    "    df.loc[(df.label_gt.notna() & df.label_pred.notna()) & (df.label_gt != df.label_pred), \"cm\"] = \"FNFP\" # CHANGED\n",
    "    \n",
    "    df.loc[\n",
    "        (df.label_pred.notna()) & (df.label_gt.notna()) & (df.label_gt == df.label_pred), \"cm\"\n",
    "    ] = \"TP\"\n",
    "\n",
    "    FP = (df[\"cm\"].isin({\"FP\", \"FNFP\"})).sum()\n",
    "    FN = (df[\"cm\"].isin({\"FN\", \"FNFP\"})).sum()\n",
    "    TP = (df[\"cm\"] == \"TP\").sum()\n",
    "    s_micro = (1+(beta**2))*TP/(((1+(beta**2))*TP) + ((beta**2)*FN) + FP)\n",
    "\n",
    "    return s_micro\n",
    "\n",
    "\n",
    "def score_feedback(pred_df, gt_df):\n",
    "    df = pred_df.merge(gt_df,how='outer',on=['document',\"token\"],suffixes=('_p','_g'))\n",
    "\n",
    "    df['status'] = \"TN\"\n",
    "\n",
    "    df.loc[df.label_gt.isna(),'status'] = \"FP\"\n",
    "    df.loc[df.label_pred.isna(),'status'] = \"FN\"\n",
    "    df.loc[(df.label_gt.notna()) & (df.label_gt!=df.label_pred),'status'] = \"FN\"\n",
    "    df.loc[(df.label_pred.notna()) & (df.label_gt.notna()) & (df.label_gt==df.label_pred),'status'] = \"TP\"\n",
    "\n",
    "    FP = (df['status'].isin([\"FP\"])).sum()\n",
    "    FN = (df['status'].isin([\"FN\"])).sum()\n",
    "    TP = (df['status']==\"TP\").sum()\n",
    "\n",
    "    s_micro = (1+(5**2))*TP/(((1+(5**2))*TP) + ((5**2)*FN) + FP)\n",
    "\n",
    "    df[\"cm\"] = \"\"\n",
    "    \n",
    "    df.loc[df.label_gt.isna(), \"cm\"] = \"FP\"\n",
    "    df.loc[df.label_pred.isna(), \"cm\"] = \"FN\"\n",
    "\n",
    "    # df.loc[(df.label_gt.notna()) & (df.label_gt != df.label_pred), \"cm\"] = \"FNFP\"\n",
    "    df.loc[(df.label_gt.notna() & df.label_pred.notna()) & (df.label_gt != df.label_pred), \"cm\"] = \"FNFP\" # CHANGED\n",
    "    \n",
    "    df.loc[\n",
    "        (df.label_pred.notna()) & (df.label_gt.notna()) & (df.label_gt == df.label_pred), \"cm\"\n",
    "    ] = \"TP\"\n",
    "\n",
    "    FP = (df[\"cm\"].isin({\"FP\", \"FNFP\"})).sum()\n",
    "    FN = (df[\"cm\"].isin({\"FN\", \"FNFP\"})).sum()\n",
    "    TP = (df[\"cm\"] == \"TP\").sum()\n",
    "    s_micro_new = (1+(5**2))*TP/(((1+(5**2))*TP) + ((5**2)*FN) + FP)\n",
    "\n",
    "\n",
    "    dic_class = {}\n",
    "    classes = gt_df['label'].unique()\n",
    "    for c in classes:\n",
    "        dx = df[(df.label_gt.isna()) | (df.label_g==c)].reset_index()\n",
    "        dx[\"cm1\"] = \"\"\n",
    "    \n",
    "        dx.loc[dx.label_gt.isna(), \"cm\"] = \"FP\"\n",
    "        dx.loc[dx.label_pred.isna(), \"cm\"] = \"FN\"\n",
    "\n",
    "        # df.loc[(df.label_gt.notna()) & (df.label_gt != df.label_pred), \"cm\"] = \"FNFP\"\n",
    "        dx.loc[(dx.label_gt.notna() & dx.label_pred.notna()) & (dx.label_gt != dx.label_pred), \"cm\"] = \"FNFP\" # CHANGED\n",
    "\n",
    "        dx.loc[\n",
    "            (dx.label_pred.notna()) & (dx.label_gt.notna()) & (dx.label_gt == dx.label_pred), \"cm\"\n",
    "        ] = \"TP\"\n",
    "\n",
    "        FP = (dx[\"cm\"].isin({\"FP\", \"FNFP\"})).sum()\n",
    "        FN = (dx[\"cm\"].isin({\"FN\", \"FNFP\"})).sum()\n",
    "        TP = (dx[\"cm\"] == \"TP\").sum()\n",
    "        s = (1+(5**2))*TP/(((1+(5**2))*TP) + ((5**2)*FN) + FP)\n",
    "    \n",
    "#         s = (1+(5**2))*tp/(((1+(5**2))*tp) + ((5**2)*fn) + fp) if tp+fp+fn !=0 else -1\n",
    "        dic_class[LABEL[c]] = s\n",
    "    # df.loc[(df.label_pred.notna()) & (df.label_gt.notna()) & (df.label_gt==df.label_pred),'status'] = \"TP\"\n",
    "\n",
    "\n",
    "    # s_micro = fbeta_score(df['label'].values, df['label_pred'].values, average='micro', beta=5)\n",
    "    # s_macro = fbeta_score(df['label'].values, df['label_pred'].values, average='macro', beta=5)\n",
    "    return s_micro_new,s_micro,dic_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de0ec9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "class PRFScore:\n",
    "    \"\"\"A precision / recall / F score.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        tp: int = 0,\n",
    "        fp: int = 0,\n",
    "        fn: int = 0,\n",
    "    ) -> None:\n",
    "        self.tp = tp\n",
    "        self.fp = fp\n",
    "        self.fn = fn\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.tp + self.fp + self.fn\n",
    "\n",
    "    def __iadd__(self, other):  # in-place add\n",
    "        self.tp += other.tp\n",
    "        self.fp += other.fp\n",
    "        self.fn += other.fn\n",
    "        return self\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return PRFScore(\n",
    "            tp=self.tp + other.tp, fp=self.fp + other.fp, fn=self.fn + other.fn\n",
    "        )\n",
    "\n",
    "    def score_set(self, cand: set, gold: set) -> None:\n",
    "        self.tp += len(cand.intersection(gold))\n",
    "        self.fp += len(cand - gold)\n",
    "        self.fn += len(gold - cand)\n",
    "\n",
    "    @property\n",
    "    def precision(self) -> float:\n",
    "        return self.tp / (self.tp + self.fp + 1e-100)\n",
    "\n",
    "    @property\n",
    "    def recall(self) -> float:\n",
    "        return self.tp / (self.tp + self.fn + 1e-100)\n",
    "\n",
    "    @property\n",
    "    def f1(self) -> float:\n",
    "        p = self.precision\n",
    "        r = self.recall\n",
    "        return 2 * ((p * r) / (p + r + 1e-100))\n",
    "\n",
    "    @property\n",
    "    def f5(self) -> float:\n",
    "        beta = 5\n",
    "        p = self.precision\n",
    "        r = self.recall\n",
    "\n",
    "        fbeta = (1+(beta**2))*p*r / ((beta**2)*p + r + 1e-100)\n",
    "        return fbeta\n",
    "\n",
    "    def to_dict(self) -> Dict[str, float]:\n",
    "        return {\"p\": self.precision, \"r\": self.recall, \"f5\": self.f5}\n",
    "\n",
    "\n",
    "def compute_metrics(pred_df, gt_df):\n",
    "    \"\"\"\n",
    "    Compute the LB metric (lb) and other auxiliary metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    references = {(row.document, row.token, row.label) for row in gt_df.itertuples()}\n",
    "    predictions = {(row.document, row.token, row.label) for row in pred_df.itertuples()}\n",
    "\n",
    "    score_per_type = defaultdict(PRFScore)\n",
    "    references = set(references)\n",
    "\n",
    "    for ex in predictions:\n",
    "        pred_type = ex[-1] # (document, token, label)\n",
    "        if pred_type != 'O':\n",
    "            pred_type = pred_type[2:] # avoid B- and I- prefix\n",
    "            \n",
    "        if pred_type not in score_per_type:\n",
    "            score_per_type[pred_type] = PRFScore()\n",
    "\n",
    "        if ex in references:\n",
    "            score_per_type[pred_type].tp += 1\n",
    "            references.remove(ex)\n",
    "        else:\n",
    "            score_per_type[pred_type].fp += 1\n",
    "\n",
    "    for doc, tok, ref_type in references:\n",
    "        if ref_type != 'O':\n",
    "            ref_type = ref_type[2:] # avoid B- and I- prefix\n",
    "        \n",
    "        if ref_type not in score_per_type:\n",
    "            score_per_type[ref_type] = PRFScore()\n",
    "        score_per_type[ref_type].fn += 1\n",
    "\n",
    "    totals = PRFScore()\n",
    "    \n",
    "    for prf in score_per_type.values():\n",
    "        totals += prf\n",
    "\n",
    "    return {\n",
    "        \"ents_p\": totals.precision,\n",
    "        \"ents_r\": totals.recall,\n",
    "        \"ents_f5\": totals.f5,\n",
    "        \"ents_per_type\": {k: v.to_dict() for k, v in score_per_type.items() if k!= 'O'},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "468b5b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ents_p': 0.8036253776435045,\n",
       " 'ents_r': 0.9851851851851852,\n",
       " 'ents_f5': 0.9766982064680132,\n",
       " 'ents_per_type': {'NAME_STUDENT': {'p': 0.8136752136752137,\n",
       "   'r': 0.9896049896049897,\n",
       "   'f5': 0.9814432989690723},\n",
       "  'ID_NUM': {'p': 0.6896551724137931,\n",
       "   'r': 0.9523809523809523,\n",
       "   'f5': 0.9386281588447652},\n",
       "  'EMAIL': {'p': 0.6, 'r': 0.75, 'f5': 0.7428571428571428},\n",
       "  'URL_PERSONAL': {'p': 0.78125, 'r': 1.0, 'f5': 0.989345509893455},\n",
       "  'PHONE_NUM': {'p': 0.8, 'r': 1.0, 'f5': 0.9904761904761905},\n",
       "  'USERNAME': {'p': 1.0, 'r': 1.0, 'f5': 1.0}}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(pred_df, gt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8235bc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976698206468013"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pii_fbeta_score_v2(pred_df, gt_df, beta=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af7ca8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.976698206468013,\n",
       " 0.9770431588613406,\n",
       " {'NAME_STUDENT': 0.9800443458980045,\n",
       "  'URL_PERSONAL': 0.8387096774193549,\n",
       "  'PHONE_NUM': 0.45414847161572053,\n",
       "  'EMAIL': 0.46846846846846846,\n",
       "  'ID_NUM': 0.7749627421758569,\n",
       "  'USERNAME': 0.17218543046357615})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_feedback(pred_df, gt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d214084d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.976698206468013,\n",
       " 0.9770431588613406,\n",
       " {'NAME_STUDENT': 0.9875518672199171,\n",
       "  'URL_PERSONAL': 0.9715994020926756,\n",
       "  'PHONE_NUM': 0.9285714285714286,\n",
       "  'EMAIL': 0.7222222222222222,\n",
       "  'ID_NUM': 0.9219858156028369,\n",
       "  'USERNAME': 0.7647058823529411})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_feedback(pred_df, gt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64110eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================================================================ #\n",
    "def pii_fbeta_score(pred_df, gt_df,beta=5):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - pred_df (DataFrame): DataFrame containing predicted PII labels.\n",
    "    - gt_df (DataFrame): DataFrame containing ground truth PII labels.\n",
    "    - beta (float): The beta parameter for the F-beta score, controlling the trade-off between precision and recall.\n",
    "\n",
    "    Returns:\n",
    "    - float: Micro F-beta score.\n",
    "    \"\"\"   \n",
    "    df = pred_df.merge(gt_df,how='outer',on=['document',\"token\"],suffixes=('_p','_g'))\n",
    "\n",
    "    df['cm'] = \"\"\n",
    "\n",
    "    df.loc[df.label_gt.isna(),'cm'] = \"FP\"\n",
    "\n",
    "\n",
    "    df.loc[df.label_pred.isna(),'cm'] = \"FN\"\n",
    "    df.loc[(df.label_gt.notna()) & (df.label_gt!=df.label_pred),'cm'] = \"FN\"\n",
    "\n",
    "    df.loc[(df.label_pred.notna()) & (df.label_gt.notna()) & (df.label_gt==df.label_pred),'cm'] = \"TP\"\n",
    "    \n",
    "    FP = (df['cm']==\"FP\").sum()\n",
    "    FN = (df['cm']==\"FN\").sum()\n",
    "    TP = (df['cm']==\"TP\").sum()\n",
    "\n",
    "    s_micro = (1+(beta**2))*TP/(((1+(beta**2))*TP) + ((beta**2)*FN) + FP)\n",
    "\n",
    "    return s_micro\n",
    "# ================================================================================================================================ #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "777a02a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9770431588613406"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pii_fbeta_score(pred_df, gt_df,beta=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd8e0081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9857468643101482, 0.9857468643101482)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_feedback(pred_df, gt_df,return_class_scores=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "637f4c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1375, 1.4458, 0.6323, 1.3729],\n",
       "        [0.7414, 0.3172, 1.1111, 1.8469]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> a = torch.randn((2,4))\n",
    ">>> b = torch.randn((2,4))\n",
    ">>> torch.max(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a15bcc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1375,  1.4458, -0.8423, -0.2943],\n",
       "         [ 0.7414,  0.1407, -1.9276,  0.2574]]),\n",
       " tensor([[-0.8673,  1.3392,  0.6323,  1.3729],\n",
       "         [-1.9609,  0.3172,  1.1111,  1.8469]]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8ef0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  micro_f1 = score(gt_df, pred_df[COL_SUBS], row_id_column_name = \"row_id\", beta = 5)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "005ec8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab = df[df[FOLD_NAME]==0].iloc[0]['labels']\n",
    "[i for i,idx in enumerate(lab) if idx!=\"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef97eb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[FOLD_NAME]==0].iloc[0]['tokens'][79]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1d2eb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_df.score.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b068f78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>20</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>20</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>20</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>20</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>20</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>20</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>20</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>20</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>20</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>20</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>20</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>20</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>20</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>20</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>20</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>20</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>20</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>20</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>20</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>20</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>20</td>\n",
       "      <td>343</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>20</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>20</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>20</td>\n",
       "      <td>378</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>20</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>20</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>20</td>\n",
       "      <td>423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>20</td>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>20</td>\n",
       "      <td>454</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>20</td>\n",
       "      <td>470</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>20</td>\n",
       "      <td>482</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>20</td>\n",
       "      <td>489</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>20</td>\n",
       "      <td>505</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>20</td>\n",
       "      <td>521</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>20</td>\n",
       "      <td>524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>20</td>\n",
       "      <td>538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>20</td>\n",
       "      <td>552</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>20</td>\n",
       "      <td>569</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>20</td>\n",
       "      <td>581</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>20</td>\n",
       "      <td>592</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>20</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>20</td>\n",
       "      <td>622</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>20</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>20</td>\n",
       "      <td>653</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>20</td>\n",
       "      <td>667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>20</td>\n",
       "      <td>686</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>20</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>20</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>20</td>\n",
       "      <td>727</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>20</td>\n",
       "      <td>741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>20</td>\n",
       "      <td>759</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>20</td>\n",
       "      <td>775</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>20</td>\n",
       "      <td>791</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>20</td>\n",
       "      <td>804</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>20</td>\n",
       "      <td>816</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>20</td>\n",
       "      <td>828</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>20</td>\n",
       "      <td>838</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>20</td>\n",
       "      <td>840</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>20</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>20</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>20</td>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>20</td>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>20</td>\n",
       "      <td>916</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>20</td>\n",
       "      <td>932</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>20</td>\n",
       "      <td>948</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>20</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>20</td>\n",
       "      <td>976</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>20</td>\n",
       "      <td>984</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>20</td>\n",
       "      <td>986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>20</td>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>20</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>20</td>\n",
       "      <td>1034</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>20</td>\n",
       "      <td>1047</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>20</td>\n",
       "      <td>1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>20</td>\n",
       "      <td>1070</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      document  token  label  score\n",
       "4           20      4      0 0.1250\n",
       "5           20      5      0 0.9831\n",
       "6           20      6      0 0.9981\n",
       "7           20      7      0 0.1250\n",
       "10          20     10      0 0.1250\n",
       "13          20     13      0 0.1250\n",
       "15          20     15      0 0.1250\n",
       "17          20     17      0 0.1250\n",
       "31          20     31      0 0.1250\n",
       "46          20     46      0 0.1250\n",
       "62          20     62      0 0.1250\n",
       "79          20     79      0 0.1250\n",
       "92          20     92      0 0.1250\n",
       "107         20    107      0 0.1250\n",
       "122         20    122      0 0.1250\n",
       "137         20    137      0 0.1250\n",
       "151         20    151      0 0.1250\n",
       "165         20    165      0 0.1250\n",
       "179         20    179      0 0.1250\n",
       "196         20    196      0 0.1250\n",
       "209         20    209      0 0.1250\n",
       "224         20    224      0 0.1250\n",
       "229         20    229      0 0.1250\n",
       "246         20    246      0 0.1250\n",
       "251         20    251      0 0.1250\n",
       "253         20    253      0 0.1250\n",
       "266         20    266      0 0.1250\n",
       "281         20    281      0 0.1250\n",
       "297         20    297      0 0.1250\n",
       "311         20    311      0 0.1250\n",
       "326         20    326      0 0.1250\n",
       "343         20    343      0 0.1250\n",
       "345         20    345      0 0.1250\n",
       "360         20    360      0 0.1250\n",
       "378         20    378      0 0.1250\n",
       "393         20    393      0 0.1250\n",
       "410         20    410      0 0.1250\n",
       "423         20    423      0 0.1250\n",
       "438         20    438      0 0.1250\n",
       "454         20    454      0 0.1250\n",
       "470         20    470      0 0.1250\n",
       "482         20    482      0 0.1250\n",
       "489         20    489      0 0.1250\n",
       "505         20    505      0 0.1250\n",
       "521         20    521      0 0.1250\n",
       "524         20    524      0 0.1250\n",
       "538         20    538      0 0.1250\n",
       "552         20    552      0 0.1250\n",
       "569         20    569      0 0.1250\n",
       "581         20    581      0 0.1250\n",
       "592         20    592      0 0.1250\n",
       "608         20    608      0 0.1250\n",
       "622         20    622      0 0.1250\n",
       "637         20    637      0 0.1250\n",
       "653         20    653      0 0.1250\n",
       "667         20    667      0 0.1250\n",
       "686         20    686      0 0.1250\n",
       "700         20    700      0 0.1250\n",
       "711         20    711      0 0.1250\n",
       "727         20    727      0 0.1250\n",
       "741         20    741      0 0.1250\n",
       "759         20    759      0 0.1250\n",
       "775         20    775      0 0.1250\n",
       "791         20    791      0 0.1250\n",
       "804         20    804      0 0.1250\n",
       "816         20    816      0 0.1250\n",
       "828         20    828      0 0.1250\n",
       "838         20    838      0 0.1250\n",
       "840         20    840      0 0.1250\n",
       "854         20    854      0 0.1250\n",
       "869         20    869      0 0.1250\n",
       "883         20    883      0 0.1250\n",
       "902         20    902      0 0.1250\n",
       "916         20    916      0 0.1250\n",
       "932         20    932      0 0.1250\n",
       "948         20    948      0 0.1250\n",
       "960         20    960      0 0.1250\n",
       "976         20    976      0 0.1250\n",
       "984         20    984      0 0.1250\n",
       "986         20    986      0 0.1250\n",
       "1002        20   1002      0 0.1250\n",
       "1020        20   1020      0 0.1250\n",
       "1034        20   1034      0 0.1250\n",
       "1047        20   1047      0 0.1250\n",
       "1065        20   1065      0 0.1250\n",
       "1070        20   1070      0 0.1250"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df[(pred_df.document==20) & (pred_df.label!=7)].head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
